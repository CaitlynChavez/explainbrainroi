{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Directory where the data is stored - this should be for a single data type/label \n",
    "# (e.g. control data only, or other label data only)\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/For_SPR/super_mini_pipeline/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.nii: (192, 256, 256)\n",
      " You have loaded  2  images\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".nii\") or filename.endswith(\".nii.gz\"): # Check for specific image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = nib.load(img_path)\n",
    "            img_data = img.get_fdata()\n",
    "            print(f\"Shape of image {filename}: {img_data.shape}\")\n",
    "            images.append(img_data)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "loaded_images = load_images_from_folder(directory)\n",
    "print(\" You have loaded \", len(loaded_images), \" images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's apply FSL ANAT to the images\n",
    "\n",
    "\n",
    "# n_jobs  = -1 # Number of jobs to run in parallel. -1 means use all available processors.\n",
    "n_jobs = 10\n",
    "\n",
    "def process_anat_volumes(directory, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Process anatomical volumes for files in a specified directory using parallel computing.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    process_anat_volumes('/path/to/your/directory/', n_jobs=8)\n",
    "    \"\"\"\n",
    "    def anat_volumes(filename):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        return subprocess.run([\"fsl_anat\", \"-i\", full_path], capture_output=True)\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(delayed(anat_volumes)(filename) for filename in os.listdir(directory))\n",
    "\n",
    "process_anat_volumes(directory, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "# took 35 mins to run 7 images on 10 cores\n",
    "# took ~ 30 mins to process 2 images on 10 cores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/md0/cads-phd/For_SPR/super_mini_pipeline/sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.anat/T1.nii.gz\n",
      "/mnt/md0/cads-phd/For_SPR/super_mini_pipeline/sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.anat/T1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Let's apply the warps to the images\n",
    "def invwarp(directory):\n",
    "\n",
    "    print(directory+\"/T1.nii.gz\")\n",
    "    return subprocess.run([\"invwarp\", \"--ref=\"+directory+\"/T1.nii.gz\", \"--warp=\"+directory+\"/T1_to_MNI_nonlin_field.nii.gz\", \"--out=\"+directory+\"/Warps/\"+\"std_subject_space\", \"--verbose\"], capture_output=True)\n",
    "\n",
    "def applywarp_cort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "def applywarp_subcort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-sub-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"subcort_HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "\n",
    "# Apply warps to files in a specified directory in parallel\n",
    "def apply_warps_parallel(directory, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Apply warps to files in a specified directory in parallel.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    apply_warps_parallel('/path/to/your/directory/', n_jobs=8)\n",
    "    \"\"\"\n",
    "    def apply_warps(path):\n",
    "        folder = os.path.join(path, \"Warps\") \n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        invwarp(path)\n",
    "        time.sleep(3)\n",
    "        applywarp_cort(path)\n",
    "        time.sleep(3)\n",
    "        applywarp_subcort(path)\n",
    "        time.sleep(3)\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n",
    "apply_warps_parallel(directory, n_jobs=15)\n",
    "\n",
    "# takes 21 mins to run 7 images on 15 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_path: /mnt/md0/cads-phd/For_SPR/super_mini_pipeline/sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.anat\n",
      "filename: sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.anat\n",
      "img_path: /mnt/md0/cads-phd/For_SPR/super_mini_pipeline/sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.anat\n",
      "filename: sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.anat\n",
      "\n",
      "FINAL DATAFRAME:\n",
      "                                             Patient Target  \\\n",
      "0  sub-A00000368_ses-20110101_acq-mprage_run-01_T1w    SPR   \n",
      "1  sub-A00000456_ses-20090101_acq-mprage_run-02_T1w    SPR   \n",
      "\n",
      "  Left Cerebral White Matter Left Cerebral Cortex  Left Lateral Ventricle  \\\n",
      "0             157016.149742         346764.330700            6727.006415    \n",
      "1             161196.980019         342422.081802            7401.044996    \n",
      "\n",
      "  Left Thalamus  Left Caudate  Left Putamen Left Pallidum     Brain-Stem  ...  \\\n",
      "0  5333.005086   3685.003514   5652.005390   1432.001366   22943.021880   ...   \n",
      "1  6192.037645   2315.014074   3860.023468   1530.009302   25591.155585   ...   \n",
      "\n",
      "  Temporal Occipital Fusiform Cortex Occipital Fusiform Gyrus  \\\n",
      "0                       2818.002687              2541.002423    \n",
      "1                       2886.017546              3129.019023    \n",
      "\n",
      "  Frontal Operculum Cortex Central Opercular Cortex Parietal Operculum Cortex  \\\n",
      "0             1616.001541              8671.008269               2551.002433    \n",
      "1             1518.009229              7280.044260               2115.012859    \n",
      "\n",
      "  Planum Polare Heschl's Gyrus (includes H1 and H2) Planum Temporale  \\\n",
      "0  2871.002738                         1082.001032      1289.001229    \n",
      "1  1867.011351                          914.005557      1055.006414    \n",
      "\n",
      "  Supracalcarine Cortex Occipital Pole  \n",
      "0           134.000128   14742.014059   \n",
      "1           144.000875   13825.084051   \n",
      "\n",
      "[2 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "# Here we generate, extract and build the dataframe for the volumes of the subcortical and cortical regions\n",
    "\n",
    "subcort_path = 'HarvardOxford_Subcortical.csv'\n",
    "cort_path = 'HarvardOxford_Cortical.csv'\n",
    "label = 'SPR'  # Not sure if you want this as a separate column or just a variable\n",
    "\n",
    "subcort_atlas = pd.read_csv(subcort_path)  # Suppose it has a column \"Label\" in the correct order\n",
    "cort_atlas = pd.read_csv(cort_path)        # Suppose it has a column \"Label\" in the correct order\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/For_SPR/super_mini_pipeline/'\n",
    "# directory = \"/some/path/with/anat/files\"   # or however you define it\n",
    "\n",
    "# A list to hold the row dictionaries for each subject\n",
    "all_rows = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".anat\"):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        print(\"img_path:\", img_path)\n",
    "        print(\"filename:\", filename)\n",
    "        \n",
    "        # Derive the patient ID from the filename (e.g., removing '.anat')\n",
    "        patient = filename[:-5]  # or whatever logic you need\n",
    "        \n",
    "        # -------------------\n",
    "        # 1) CORTICAL STATS\n",
    "        # -------------------\n",
    "        out_cort = subprocess.Popen(\n",
    "            [\n",
    "                \"fslstats\", \n",
    "                \"-K\", img_path + \"/Warps/HO_in_subj_t1_space.nii.gz\", \n",
    "                img_path + \"/T1.nii.gz\", \n",
    "                \"-V\"\n",
    "            ],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT\n",
    "        )\n",
    "        stdout_cort, stderr_cort = out_cort.communicate()\n",
    "        \n",
    "        cort_df = stdout_cort.decode(\"utf-8\")\n",
    "        df_cort = pd.DataFrame(\n",
    "            cort_df.replace('\\n', ',').split(\",\"), \n",
    "            columns=['vol']\n",
    "        )\n",
    "        df_cort['vol'] = df_cort['vol'].str.replace(',', '', regex=True)\n",
    "        df_cort[['Voxel', 'Volume']] = df_cort['vol'].str.split(' ', 1, expand=True)\n",
    "        df_cort = df_cort.drop(columns='vol')\n",
    "        \n",
    "        # -------------------\n",
    "        # 2) SUBCORT STATS\n",
    "        # -------------------\n",
    "        process = subprocess.Popen(\n",
    "            [\n",
    "                \"fslstats\",\n",
    "                \"-K\", img_path + \"/Warps/subcort_HO_in_subj_t1_space.nii.gz\",\n",
    "                img_path + \"/T1.nii.gz\",\n",
    "                \"-V\"\n",
    "            ],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT\n",
    "        )\n",
    "        stdout_subcort, stderr_subcort = process.communicate()\n",
    "        \n",
    "        subcort_df = stdout_subcort.decode(\"utf-8\")\n",
    "        df_subcort = pd.DataFrame(\n",
    "            subcort_df.replace('\\n', ',').split(\",\"), \n",
    "            columns=['vol']\n",
    "        )\n",
    "        df_subcort['vol'] = df_subcort['vol'].str.replace(',', '', regex=True)\n",
    "        df_subcort[['Voxel', 'Volume']] = df_subcort['vol'].str.split(' ', 1, expand=True)\n",
    "        df_subcort = df_subcort.drop(columns='vol')\n",
    "        \n",
    "        # ----------------------------\n",
    "        # 3) BUILD DICTIONARY FOR ROW\n",
    "        # ----------------------------\n",
    "        # Ensure the lengths match expected # of labels; \n",
    "        # the order in subcort_atlas['Label'] matches df_subcort['Volume'] row by row\n",
    "        subcort_dict = dict(zip(subcort_atlas['Label'], df_subcort['Volume']))\n",
    "        cort_dict    = dict(zip(cort_atlas['Label'],   df_cort['Volume']))\n",
    "        \n",
    "        # Merge them into a single dict\n",
    "        row_dict = {**subcort_dict, **cort_dict}\n",
    "        \n",
    "        # Add additional columns\n",
    "        row_dict[\"Patient\"] = patient\n",
    "        row_dict[\"Target\"]  = label  # e.g., \"SPR\", or rename to \"target\" etc.\n",
    "        \n",
    "        # ---------------------------\n",
    "        # 4) APPEND to all_rows list\n",
    "        # ---------------------------\n",
    "        all_rows.append(row_dict)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5) BUILD A FINAL DATAFRAME FROM all_rows\n",
    "# ------------------------------------------\n",
    "volume_df = pd.DataFrame(all_rows)\n",
    "\n",
    "# If you want specific ordering of columns,\n",
    "# define the order you want:\n",
    "# e.g. columns for patient, your label, then subcort, then cort\n",
    "ordered_cols = (\n",
    "    [\"Patient\", \"Target\"] \n",
    "    + subcort_atlas[\"Label\"].tolist()\n",
    "    + cort_atlas[\"Label\"].tolist()\n",
    ")\n",
    "# Reindex volume_df to enforce that order (only if you want to be strict):\n",
    "volume_df = volume_df.reindex(columns=ordered_cols)\n",
    "\n",
    "print(\"\\nFINAL DATAFRAME:\\n\")\n",
    "volume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a CSV file\n",
    "# volume_df.to_csv(\"volume_data.csv\", index=False)  # uncomment to save volumetric data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Left Cerebral White Matter</th>\n",
       "      <th>Left Cerebral Cortex</th>\n",
       "      <th>Left Lateral Ventricle</th>\n",
       "      <th>Left Thalamus</th>\n",
       "      <th>Left Caudate</th>\n",
       "      <th>Left Putamen</th>\n",
       "      <th>Left Pallidum</th>\n",
       "      <th>Brain-Stem</th>\n",
       "      <th>Left Hippocampus</th>\n",
       "      <th>...</th>\n",
       "      <th>Frontal Operculum Cortex</th>\n",
       "      <th>Central Opercular Cortex</th>\n",
       "      <th>Parietal Operculum Cortex</th>\n",
       "      <th>Planum Polare</th>\n",
       "      <th>Heschl's Gyrus (includes H1 and H2)</th>\n",
       "      <th>Planum Temporale</th>\n",
       "      <th>Supracalcarine Cortex</th>\n",
       "      <th>Occipital Pole</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-A00000368_ses-20110101_acq-mprage_run-01_T1w</th>\n",
       "      <td>SPR</td>\n",
       "      <td>157016.149742</td>\n",
       "      <td>346764.330700</td>\n",
       "      <td>6727.006415</td>\n",
       "      <td>5333.005086</td>\n",
       "      <td>3685.003514</td>\n",
       "      <td>5652.005390</td>\n",
       "      <td>1432.001366</td>\n",
       "      <td>22943.021880</td>\n",
       "      <td>2890.002756</td>\n",
       "      <td>...</td>\n",
       "      <td>1616.001541</td>\n",
       "      <td>8671.008269</td>\n",
       "      <td>2551.002433</td>\n",
       "      <td>2871.002738</td>\n",
       "      <td>1082.001032</td>\n",
       "      <td>1289.001229</td>\n",
       "      <td>134.000128</td>\n",
       "      <td>14742.014059</td>\n",
       "      <td>52</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-A00000456_ses-20090101_acq-mprage_run-02_T1w</th>\n",
       "      <td>SPR</td>\n",
       "      <td>161196.980019</td>\n",
       "      <td>342422.081802</td>\n",
       "      <td>7401.044996</td>\n",
       "      <td>6192.037645</td>\n",
       "      <td>2315.014074</td>\n",
       "      <td>3860.023468</td>\n",
       "      <td>1530.009302</td>\n",
       "      <td>25591.155585</td>\n",
       "      <td>3059.018598</td>\n",
       "      <td>...</td>\n",
       "      <td>1518.009229</td>\n",
       "      <td>7280.044260</td>\n",
       "      <td>2115.012859</td>\n",
       "      <td>1867.011351</td>\n",
       "      <td>914.005557</td>\n",
       "      <td>1055.006414</td>\n",
       "      <td>144.000875</td>\n",
       "      <td>13825.084051</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Target  \\\n",
       "Patient                                                   \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w    SPR   \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w    SPR   \n",
       "\n",
       "                                                 Left Cerebral White Matter  \\\n",
       "Patient                                                                       \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w             157016.149742    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w             161196.980019    \n",
       "\n",
       "                                                 Left Cerebral Cortex   \\\n",
       "Patient                                                                  \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w        346764.330700    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w        342422.081802    \n",
       "\n",
       "                                                 Left Lateral Ventricle  \\\n",
       "Patient                                                                   \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w           6727.006415    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w           7401.044996    \n",
       "\n",
       "                                                 Left Thalamus  Left Caudate  \\\n",
       "Patient                                                                        \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w  5333.005086   3685.003514    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w  6192.037645   2315.014074    \n",
       "\n",
       "                                                  Left Putamen Left Pallidum  \\\n",
       "Patient                                                                        \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w  5652.005390   1432.001366    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w  3860.023468   1530.009302    \n",
       "\n",
       "                                                     Brain-Stem  \\\n",
       "Patient                                                           \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w  22943.021880    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w  25591.155585    \n",
       "\n",
       "                                                 Left Hippocampus  ...  \\\n",
       "Patient                                                            ...   \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w     2890.002756   ...   \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w     3059.018598   ...   \n",
       "\n",
       "                                                 Frontal Operculum Cortex  \\\n",
       "Patient                                                                     \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w             1616.001541    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w             1518.009229    \n",
       "\n",
       "                                                 Central Opercular Cortex  \\\n",
       "Patient                                                                     \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w             8671.008269    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w             7280.044260    \n",
       "\n",
       "                                                 Parietal Operculum Cortex  \\\n",
       "Patient                                                                      \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w              2551.002433    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w              2115.012859    \n",
       "\n",
       "                                                 Planum Polare  \\\n",
       "Patient                                                          \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w  2871.002738    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w  1867.011351    \n",
       "\n",
       "                                                 Heschl's Gyrus (includes H1 and H2)  \\\n",
       "Patient                                                                                \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w                        1082.001032    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w                         914.005557    \n",
       "\n",
       "                                                 Planum Temporale  \\\n",
       "Patient                                                             \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w     1289.001229    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w     1055.006414    \n",
       "\n",
       "                                                 Supracalcarine Cortex  \\\n",
       "Patient                                                                  \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w           134.000128    \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w           144.000875    \n",
       "\n",
       "                                                 Occipital Pole age   sex  \n",
       "Patient                                                                    \n",
       "sub-A00000368_ses-20110101_acq-mprage_run-01_T1w  14742.014059   52  male  \n",
       "sub-A00000456_ses-20090101_acq-mprage_run-02_T1w  13825.084051   53  male  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now build the final dataframe by merging the processed and extracted volume data and merging it with the original data containing age and sex. \n",
    "\n",
    "original = pd.read_csv('CN_SPR_originalData.csv')\n",
    "original\n",
    "\n",
    "final_df = pd.merge(volume_df, original, on=\"Patient\")\n",
    "final_df = final_df.set_index('Patient')  # index on Patient \n",
    "to_drop = ['dx', 'Z max', 'center X', 'cener Y', 'study', 'participant_id']\n",
    "final_df = final_df.drop(columns=to_drop)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe to a CSV file\n",
    "# final_df.to_csv(\"final_data.csv\", index=True)  # uncomment to save the final dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please see the ------ for the model building code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
