{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image sub-A00000541_ses-20100101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000838_ses-20100101_acq-mprage_run-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000865_ses-20100101_acq-mprage_echo-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000844_ses-20100101_acq-mprage_echo-01_T1w.nii: (192, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# pip install joblib\n",
    "# pip install nibabel \n",
    "# !pip install matplotlib\n",
    "# !pwd\n",
    "\n",
    "# !pip install scikit-image\n",
    "# !pip install plotly\n",
    "\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".nii\") or filename.endswith(\".nii.gz\"): # Check for specific image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = nib.load(img_path)\n",
    "            img_data = img.get_fdata()\n",
    "            print(f\"Shape of image {filename}: {img_data.shape}\")\n",
    "            images.append(img_data)\n",
    "    return np.array(images)\n",
    "\n",
    "# Example usage:\n",
    "path = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'\n",
    "folder_path = path # Replace with the path to your folder\n",
    "loaded_images = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in loaded_images:\n",
    "    print(i.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/md0/cads-phd/explainbrainROI/hello.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(loaded_images)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mnt\u001b[39m/\u001b[39mmd0\u001b[39m/\u001b[39mcads\u001b[39m-\u001b[39mphd\u001b[39m/\u001b[39mexplainbrainROI\u001b[39m/\u001b[39mspr_mini_try_again()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnt' is not defined"
     ]
    }
   ],
   "source": [
    "len(loaded_images)\n",
    "\n",
    "/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Requirement already satisfied: tqdm in /home/caitlyn/.local/lib/python3.8/site-packages (4.61.2)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3109, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2902, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "    parsed = _parse_requirement(requirement_string)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 120, in _parse_requirement_details\n",
      "    specifier = _parse_specifier(tokenizer)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 217, in _parse_specifier\n",
      "    tokenizer.consume(\"WS\")\n",
      "  File \"/usr/lib/python3.8/contextlib.py\", line 120, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 187, in enclosing_tokens\n",
      "    self.raise_syntax_error(\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "    raise ParserSyntaxError(\n",
      "pkg_resources.extern.packaging._tokenizer.ParserSyntaxError: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 543, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2822, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3111, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3121, in _compute_dependencies\n",
      "    reqs.extend(parse_requirements(req))\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3174, in __init__\n",
      "    super(Requirement, self).__init__(requirement_string)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "    raise InvalidRequirement(str(e)) from e\n",
      "pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Running FSL ANAT and getting FSL ANAT Folders \n",
    "\n",
    "# n_jobs  = -1 # Number of jobs to run in parallel. -1 means use all available processors.\n",
    "n_jobs = 10\n",
    "\n",
    "def process_anat_volumes(directory, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Process anatomical volumes for files in a specified directory using parallel computing.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    process_anat_volumes('/path/to/your/directory/', n_jobs=8)\n",
    "    \"\"\"\n",
    "    def anat_volumes(filename):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        return subprocess.run([\"fsl_anat\", \"-i\", full_path], capture_output=True)\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(delayed(anat_volumes)(filename) for filename in os.listdir(directory))\n",
    "\n",
    "process_anat_volumes(directory, n_jobs=n_jobs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# upon running the above which is a function, it will return a subprocess.CompletedProcess object containing information about the completed process.\n",
    "# a folder with various files will be created in the directory where the function is run.  This folder will be named after the file that was processed and will contain the following files:\n",
    "#  the naming will be example_patient.nii.gz --> example_patient.anat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "# import time\n",
    "# import glob\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'\n",
    "\n",
    "# def invwarp(directory, ref_file, warp_file, out_file_name, verbose=False):\n",
    "#     \"\"\"\n",
    "#     Run the FSL command 'invwarp' to invert a non-linear warp field.\n",
    "\n",
    "#     Parameters:\n",
    "#     directory (str): The directory path where the files are located.\n",
    "#     ref_file (str): The reference file in the specified directory.\n",
    "#     warp_file (str): The warp file in the specified directory.\n",
    "#     out_file_name (str): The name of the output file.\n",
    "#     verbose (bool): If True, display verbose output (default is False).\n",
    "\n",
    "#     Returns:\n",
    "#     CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "#     Example:\n",
    "#     invwarp('/path/to/your/directory/', 'T1.nii.gz', 'T1_to_MNI_nonlin_field.nii.gz', 'std_subject_space', verbose=True)\n",
    "#     \"\"\"\n",
    "#     ref_path = f\"{directory}/{ref_file}\"\n",
    "#     warp_path = f\"{directory}/{warp_file}\"\n",
    "#     out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "#     verbose_arg = \"--verbose\" if verbose else \"\"\n",
    "\n",
    "#     return subprocess.run([\"invwarp\", f\"--ref={ref_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", verbose_arg], capture_output=True)\n",
    "\n",
    "\n",
    "# # For the Cortical Regions- pulling from FSL_Anat Folder \n",
    "\n",
    "\n",
    "\n",
    "# def applywarp_cort(directory, ref_file, in_file, warp_file, out_file_name, interp_method='nn'):\n",
    "#     \"\"\"\n",
    "#     Apply a warp to an input file and resample it to the space of a reference file.\n",
    "\n",
    "#     Parameters:\n",
    "#     directory (str): The directory path where the files are located.\n",
    "#     ref_file (str): The reference file in the specified directory.\n",
    "#     in_file (str): The input file to be warped.\n",
    "#     warp_file (str): The warp file in the specified directory.\n",
    "#     out_file_name (str): The name of the output file.\n",
    "#     interp_method (str): The interpolation method to be used (default is 'nn').\n",
    "\n",
    "#     Returns:\n",
    "#     CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "#     Example:\n",
    "#     applywarp_cort('/path/to/your/directory/', 'T1.nii.gz', 'HarvardOxford-cort-maxprob-thr50-2mm.nii.gz', 'std_subject_space.nii.gz', 'HO_in_subj_t1_space.nii.gz', interp_method='trilinear')\n",
    "#     \"\"\"\n",
    "#     ref_path = f\"{directory}/{ref_file}\"\n",
    "#     in_path = f\"/usr/local/fsl/data/atlases/HarvardOxford/{in_file}\"\n",
    "#     warp_path = f\"{directory}/Warps/{warp_file}\"\n",
    "#     out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "\n",
    "#     return subprocess.run([\"applywarp\", f\"--ref={ref_path}\", f\"--in={in_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", f\"--interp={interp_method}\"], capture_output=True)\n",
    "\n",
    "\n",
    "\n",
    "# def applywarp_subcort(directory, ref_file, in_file, warp_file, out_file_name, interp_method='nn'):\n",
    "#     \"\"\"\n",
    "#     Apply a warp to an input file and resample it to the space of a reference file.\n",
    "\n",
    "#     Parameters:\n",
    "#     directory (str): The directory path where the files are located.\n",
    "#     ref_file (str): The reference file in the specified directory.\n",
    "#     in_file (str): The input file to be warped.\n",
    "#     warp_file (str): The warp file in the specified directory.\n",
    "#     out_file_name (str): The name of the output file.\n",
    "#     interp_method (str): The interpolation method to be used (default is 'nn').\n",
    "\n",
    "#     Returns:\n",
    "#     CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "#     Example:\n",
    "#     applywarp_subcort('/path/to/your/directory/', 'T1.nii.gz', 'HarvardOxford-sub-maxprob-thr50-2mm.nii.gz', 'std_subject_space.nii.gz', 'subcort_HO_in_subj_t1_space.nii.gz', interp_method='trilinear')\n",
    "#     \"\"\"\n",
    "#     ref_path = f\"{directory}/{ref_file}\"\n",
    "#     in_path = f\"/usr/local/fsl/data/atlases/HarvardOxford/{in_file}\"\n",
    "#     warp_path = f\"{directory}/Warps/{warp_file}\"\n",
    "#     out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "\n",
    "#     return subprocess.run([\"applywarp\", f\"--ref={ref_path}\", f\"--in={in_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", f\"--interp={interp_method}\"], capture_output=True)\n",
    "\n",
    "\n",
    "# def apply_warps(path):\n",
    "#     \"\"\"\n",
    "#     Apply warps to specified files and save the results in the 'Warps' folder.\n",
    "\n",
    "#     Parameters:\n",
    "#     path (str): The directory path where the files are located.\n",
    "\n",
    "#     Returns:\n",
    "#     None\n",
    "\n",
    "#     Example:\n",
    "#     apply_warps('/path/to/your/directory/')\n",
    "#     \"\"\"\n",
    "#     folder = os.path.join(path, \"Warps\") \n",
    "#     if not os.path.exists(folder):\n",
    "#         os.mkdir(folder)\n",
    "\n",
    "#     invwarp(path)\n",
    "#     time.sleep(3)  # Sleep for 3 seconds to ensure completion before the next step\n",
    "#     applywarp_cort(path)\n",
    "#     applywarp_subcort(path)\n",
    "\n",
    "\n",
    "\n",
    "# def apply_warps_parallel(directory, n_jobs=6):\n",
    "#     \"\"\"\n",
    "#     Apply warps to files in a specified directory in parallel.\n",
    "\n",
    "#     Parameters:\n",
    "#     directory (str): The directory path where the files are located.\n",
    "#     n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "#     Returns:\n",
    "#     None\n",
    "\n",
    "#     Example:\n",
    "#     apply_warps_parallel('/path/to/your/directory/', n_jobs=8)\n",
    "#     \"\"\"\n",
    "#     def apply_warps(path):\n",
    "#         folder = os.path.join(path, \"Warps\") \n",
    "#         if not os.path.exists(folder):\n",
    "#             os.mkdir(folder)\n",
    "\n",
    "#         invwarp(path)\n",
    "#         time.sleep(3)  # Sleep for 3 seconds to ensure completion before the next step\n",
    "#         applywarp_cort(path)\n",
    "#         applywarp_subcort(path)\n",
    "\n",
    "#     Parallel(n_jobs=n_jobs)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n",
    "\n",
    "# apply_warps_parallel(directory, n_jobs=15)\n",
    "# #questions to be asked\n",
    "\n",
    "# # How long does this take for each image? \n",
    "# # How long does this take for all images?\n",
    "    \n",
    "# # What folders does this pull from?\n",
    "# # Do i need to move folders? \n",
    "\n",
    "# # What is the output?\n",
    "\n",
    "\n",
    "# # What function do I need to run to get a total output? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "# # import time\n",
    "# import glob\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "# directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'  #to practice on how pipeline will run with multiple images \n",
    "\n",
    "# def invwarp(directory):\n",
    "#     return subprocess.run([\"invwarp\", \"--ref=\"+directory+\"/T1.nii.gz\", \"--warp=\"+directory+\"/T1_to_MNI_nonlin_field.nii.gz\", \"--out=\"+directory+\"/Warps/\"+\"std_subject_space\", \"--verbose\"], capture_output=True)\n",
    "\n",
    "\n",
    "# def applywarp_cort(directory):\n",
    "#     return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr50-2mm.nii.gz\", \n",
    "#                \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "#                \"--out=\"+directory+\"/Warps/\"+\"HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "# def applywarp_subcort(directory):\n",
    "#     return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-sub-maxprob-thr50-2mm.nii.gz\", \n",
    "#                \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "#                \"--out=\"+directory+\"/Warps/\"+\"subcort_HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "\n",
    "# def apply_warps(path):\n",
    "    \n",
    "#     folder = os.path.join(path, \"Warps\") \n",
    "#     if not os.path.exists(folder):\n",
    "#         os.mkdir(folder)\n",
    "\n",
    "#     invwarp(path)\n",
    "#     print(path + ' invwarp done')\n",
    "#     time.sleep(3)\n",
    "#     applywarp_cort(path)\n",
    "#     print(path + ' cort done')\n",
    "#     applywarp_subcort(path)\n",
    "#     print(path + ' subcort done')\n",
    "\n",
    "#     from joblib import Parallel, delayed\n",
    "# Parallel(n_jobs=10)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat invwarp done\n",
      "/mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat cort done\n",
      "/mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat subcort done\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# /mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat\n",
    "# directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'  #to practice on how pipeline will run with multiple images \n",
    "# /mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat\n",
    "directory = '/mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat'  #to practice on how pipeline will run with multiple images \n",
    "\n",
    "\n",
    "def invwarp(directory):\n",
    "    return subprocess.run([\"invwarp\", \"--ref=\"+directory+\"/T1.nii.gz\", \"--warp=\"+directory+\"/T1_to_MNI_nonlin_field.nii.gz\", \"--out=\"+directory+\"/Warps/\"+\"std_subject_space\", \"--verbose\"], capture_output=True)\n",
    "\n",
    "\n",
    "def applywarp_cort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "def applywarp_subcort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-sub-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"subcort_HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "\n",
    "def apply_warps(path):\n",
    "    \n",
    "    folder = os.path.join(path, \"Warps\") \n",
    "    print(path)\n",
    "    # if not os.path.exists(folder):\n",
    "    #     os.mkdir(folder)\n",
    "\n",
    "    invwarp(path)\n",
    "    print(path + ' invwarp done')\n",
    "    time.sleep(3)\n",
    "    applywarp_cort(path)\n",
    "    print(path + ' cort done')\n",
    "    applywarp_subcort(path)\n",
    "    print(path + ' subcort done')\n",
    "\n",
    "apply_warps(os.path.join(directory))\n",
    "\n",
    "#     from joblib import Parallel, delayed\n",
    "# Parallel(n_jobs=10)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /mnt/md0/cads-phd/explainbrainROI/run_dir/ca/sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.anat/Warps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fslstats -K subcort_HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the subcortical regions\n",
    "# fslstats -K HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the cortical regions\n",
    "\n",
    "\n",
    "def get_vols(vol_files, label):\n",
    "    \n",
    "    patient = {}\n",
    "    \n",
    "    for file in vol_files:\n",
    "        \n",
    "        path = os.path.basename(file)\n",
    "        \n",
    "        label_vals = [10, 11, 12, 13, 16, 17, 18, 26, 49, 50, 51, 52, 53, 54, 58]\n",
    "        length = len(label_vals)\n",
    "\n",
    "        vols = {}\n",
    "        \n",
    "        \n",
    "        for i in label_vals:\n",
    "            out = sout = subprocess.Popen([\"fslstats\", file, \"-l\", str((i+0.5)-1), \"-u\", str(i+0.5), \"-V\"], \n",
    "                   stdout=subprocess.PIPE, \n",
    "                   stderr=subprocess.STDOUT)\n",
    "            stdout,stderr = out.communicate()\n",
    "            vols[\"LABEL\"] = label\n",
    "            vols[str(i)] = [float(str(stdout.split()[0])[2:-1]), float(str(stdout.split()[1])[2:-1])]\n",
    "\n",
    "        patient[path[:-29]] = vols\n",
    "    \n",
    "    return patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fslstats -K subcort_HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the subcortical regions\n",
    "# fslstats -K HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the cortical regions\n",
    "\n",
    "# I need to\n",
    "# 1. feed in the parent directory\n",
    "# 2. feed in the label for each file and where the file is located\n",
    "# 3. apply fslstats for cort and applywarp_subcort\n",
    "# 4. collect the outputs and feed into dictionary\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def getVol_Dataframe(directory):\n",
    "\n",
    "    brain_volumes = pd.DataFrame()\n",
    "\n",
    "    for file in glob.glob(os.path.join(directory)):\n",
    "\n",
    "        path = os.path.basename(file)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        # vols = {}\n",
    "\n",
    "        # for i in label_vals:\n",
    "        #     print(i)\n",
    "        #     out_cort = sout = subprocess.Popen([\"fslstats\", \"-K\", \"./Warps/HO_in_subj_t1_space.nii.gz\", \"T1.nii.gz\", \"-V\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        #     stdout,stderr = out.communicate()\n",
    "        #     out_subcort = sout = subprocess.Popen([\"fslstats\", \"-K\", \"./Warps/subcort_HO_in_subj_t1_space.nii.gz\", \"T1.nii.gz\", \"-V\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        #     stdout,stderr = out.communicate()\n",
    "\n",
    "        #     vols[\"LABEL\"] = label\n",
    "        #     vols[str(i)] = [float(str(stdout.split()[0])[2:-1]), float(str(stdout.split()[1])[2:-1])]\n",
    "\n",
    "        # patient[path[:-29]] = vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'  #to practice on how pipeline will run with multiple images \n",
    "\n",
    "for file in glob.glob(os.path.join(directory)):\n",
    "    \n",
    "    path = os.path.basename(file)\n",
    "\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
