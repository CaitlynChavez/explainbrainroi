{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image sub-A00000541_ses-20100101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000456_ses-20090101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000838_ses-20100101_acq-mprage_run-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000368_ses-20110101_acq-mprage_run-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000909_ses-20110101_acq-mprage_run-02_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000865_ses-20100101_acq-mprage_echo-01_T1w.nii: (192, 256, 256)\n",
      "Shape of image sub-A00000844_ses-20100101_acq-mprage_echo-01_T1w.nii: (192, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# pip install joblib\n",
    "# pip install nibabel \n",
    "# !pip install matplotlib\n",
    "# !pwd\n",
    "\n",
    "# !pip install scikit-image\n",
    "# !pip install plotly\n",
    "\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".nii\") or filename.endswith(\".nii.gz\"): # Check for specific image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = nib.load(img_path)\n",
    "            img_data = img.get_fdata()\n",
    "            print(f\"Shape of image {filename}: {img_data.shape}\")\n",
    "            images.append(img_data)\n",
    "    return np.array(images)\n",
    "\n",
    "# Example usage:\n",
    "path = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'\n",
    "folder_path = path # Replace with the path to your folder\n",
    "loaded_images = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n",
      "(192, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in loaded_images:\n",
    "    print(i.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_images)\n",
    "\n",
    "/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Requirement already satisfied: tqdm in /home/caitlyn/.local/lib/python3.8/site-packages (4.61.2)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3109, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2902, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "    parsed = _parse_requirement(requirement_string)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 120, in _parse_requirement_details\n",
      "    specifier = _parse_specifier(tokenizer)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 217, in _parse_specifier\n",
      "    tokenizer.consume(\"WS\")\n",
      "  File \"/usr/lib/python3.8/contextlib.py\", line 120, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 187, in enclosing_tokens\n",
      "    self.raise_syntax_error(\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "    raise ParserSyntaxError(\n",
      "pkg_resources.extern.packaging._tokenizer.ParserSyntaxError: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 543, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2822, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3111, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3121, in _compute_dependencies\n",
      "    reqs.extend(parse_requirements(req))\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3174, in __init__\n",
      "    super(Requirement, self).__init__(requirement_string)\n",
      "  File \"/home/caitlyn/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "    raise InvalidRequirement(str(e)) from e\n",
      "pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Running FSL ANAT and getting FSL ANAT Folders \n",
    "\n",
    "# n_jobs  = -1 # Number of jobs to run in parallel. -1 means use all available processors.\n",
    "n_jobs = 10\n",
    "\n",
    "def process_anat_volumes(directory, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Process anatomical volumes for files in a specified directory using parallel computing.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    process_anat_volumes('/path/to/your/directory/', n_jobs=8)\n",
    "    \"\"\"\n",
    "    def anat_volumes(filename):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        return subprocess.run([\"fsl_anat\", \"-i\", full_path], capture_output=True)\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(delayed(anat_volumes)(filename) for filename in os.listdir(directory))\n",
    "\n",
    "process_anat_volumes(directory, n_jobs=n_jobs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# upon running the above which is a function, it will return a subprocess.CompletedProcess object containing information about the completed process.\n",
    "# a folder with various files will be created in the directory where the function is run.  This folder will be named after the file that was processed and will contain the following files:\n",
    "#  the naming will be example_patient.nii.gz --> example_patient.anat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invwarp() missing 3 required positional arguments: 'ref_file', 'warp_file', and 'out_file_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/caitlyn/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/caitlyn/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/caitlyn/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/caitlyn/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_13796/3593228205.py\", line 134, in apply_warps\nTypeError: invwarp() missing 3 required positional arguments: 'ref_file', 'warp_file', and 'out_file_name'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/md0/cads-phd/explainbrainROI/hello.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m         applywarp_subcort(path)\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs)(delayed(apply_warps)(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, \u001b[39m'\u001b[39m\u001b[39m*.anat\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m apply_warps_parallel(directory, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/md0/cads-phd/explainbrainROI/hello.ipynb Cell 7\u001b[0m line \u001b[0;36mapply_warps_parallel\u001b[0;34m(directory, n_jobs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     applywarp_cort(path)\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     applywarp_subcort(path)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/mnt/md0/cads-phd/explainbrainROI/hello.ipynb#W6sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs)(delayed(apply_warps)(file) \u001b[39mfor\u001b[39;49;00m file \u001b[39min\u001b[39;49;00m glob\u001b[39m.\u001b[39;49mglob(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(directory, \u001b[39m'\u001b[39;49m\u001b[39m*.anat\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[1;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[1;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: invwarp() missing 3 required positional arguments: 'ref_file', 'warp_file', and 'out_file_name'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'\n",
    "\n",
    "def invwarp(directory, ref_file, warp_file, out_file_name, verbose=False):\n",
    "    \"\"\"\n",
    "    Run the FSL command 'invwarp' to invert a non-linear warp field.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    ref_file (str): The reference file in the specified directory.\n",
    "    warp_file (str): The warp file in the specified directory.\n",
    "    out_file_name (str): The name of the output file.\n",
    "    verbose (bool): If True, display verbose output (default is False).\n",
    "\n",
    "    Returns:\n",
    "    CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "    Example:\n",
    "    invwarp('/path/to/your/directory/', 'T1.nii.gz', 'T1_to_MNI_nonlin_field.nii.gz', 'std_subject_space', verbose=True)\n",
    "    \"\"\"\n",
    "    ref_path = f\"{directory}/{ref_file}\"\n",
    "    warp_path = f\"{directory}/{warp_file}\"\n",
    "    out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "    verbose_arg = \"--verbose\" if verbose else \"\"\n",
    "\n",
    "    return subprocess.run([\"invwarp\", f\"--ref={ref_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", verbose_arg], capture_output=True)\n",
    "\n",
    "\n",
    "# For the Cortical Regions- pulling from FSL_Anat Folder \n",
    "\n",
    "\n",
    "\n",
    "def applywarp_cort(directory, ref_file, in_file, warp_file, out_file_name, interp_method='nn'):\n",
    "    \"\"\"\n",
    "    Apply a warp to an input file and resample it to the space of a reference file.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    ref_file (str): The reference file in the specified directory.\n",
    "    in_file (str): The input file to be warped.\n",
    "    warp_file (str): The warp file in the specified directory.\n",
    "    out_file_name (str): The name of the output file.\n",
    "    interp_method (str): The interpolation method to be used (default is 'nn').\n",
    "\n",
    "    Returns:\n",
    "    CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "    Example:\n",
    "    applywarp_cort('/path/to/your/directory/', 'T1.nii.gz', 'HarvardOxford-cort-maxprob-thr50-2mm.nii.gz', 'std_subject_space.nii.gz', 'HO_in_subj_t1_space.nii.gz', interp_method='trilinear')\n",
    "    \"\"\"\n",
    "    ref_path = f\"{directory}/{ref_file}\"\n",
    "    in_path = f\"/usr/local/fsl/data/atlases/HarvardOxford/{in_file}\"\n",
    "    warp_path = f\"{directory}/Warps/{warp_file}\"\n",
    "    out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "\n",
    "    return subprocess.run([\"applywarp\", f\"--ref={ref_path}\", f\"--in={in_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", f\"--interp={interp_method}\"], capture_output=True)\n",
    "\n",
    "\n",
    "\n",
    "def applywarp_subcort(directory, ref_file, in_file, warp_file, out_file_name, interp_method='nn'):\n",
    "    \"\"\"\n",
    "    Apply a warp to an input file and resample it to the space of a reference file.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    ref_file (str): The reference file in the specified directory.\n",
    "    in_file (str): The input file to be warped.\n",
    "    warp_file (str): The warp file in the specified directory.\n",
    "    out_file_name (str): The name of the output file.\n",
    "    interp_method (str): The interpolation method to be used (default is 'nn').\n",
    "\n",
    "    Returns:\n",
    "    CompletedProcess: A subprocess.CompletedProcess object containing information about the completed process.\n",
    "\n",
    "    Example:\n",
    "    applywarp_subcort('/path/to/your/directory/', 'T1.nii.gz', 'HarvardOxford-sub-maxprob-thr50-2mm.nii.gz', 'std_subject_space.nii.gz', 'subcort_HO_in_subj_t1_space.nii.gz', interp_method='trilinear')\n",
    "    \"\"\"\n",
    "    ref_path = f\"{directory}/{ref_file}\"\n",
    "    in_path = f\"/usr/local/fsl/data/atlases/HarvardOxford/{in_file}\"\n",
    "    warp_path = f\"{directory}/Warps/{warp_file}\"\n",
    "    out_path = f\"{directory}/Warps/{out_file_name}\"\n",
    "\n",
    "    return subprocess.run([\"applywarp\", f\"--ref={ref_path}\", f\"--in={in_path}\", f\"--warp={warp_path}\", f\"--out={out_path}\", f\"--interp={interp_method}\"], capture_output=True)\n",
    "\n",
    "\n",
    "def apply_warps(path):\n",
    "    \"\"\"\n",
    "    Apply warps to specified files and save the results in the 'Warps' folder.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The directory path where the files are located.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    apply_warps('/path/to/your/directory/')\n",
    "    \"\"\"\n",
    "    folder = os.path.join(path, \"Warps\") \n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    invwarp(path)\n",
    "    time.sleep(3)  # Sleep for 3 seconds to ensure completion before the next step\n",
    "    applywarp_cort(path)\n",
    "    applywarp_subcort(path)\n",
    "\n",
    "\n",
    "\n",
    "def apply_warps_parallel(directory, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Apply warps to files in a specified directory in parallel.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory path where the files are located.\n",
    "    n_jobs (int): The number of jobs to run in parallel (default is 6).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    apply_warps_parallel('/path/to/your/directory/', n_jobs=8)\n",
    "    \"\"\"\n",
    "    def apply_warps(path):\n",
    "        folder = os.path.join(path, \"Warps\") \n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        invwarp(path)\n",
    "        time.sleep(3)  # Sleep for 3 seconds to ensure completion before the next step\n",
    "        applywarp_cort(path)\n",
    "        applywarp_subcort(path)\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n",
    "\n",
    "apply_warps_parallel(directory, n_jobs=15)\n",
    "#questions to be asked\n",
    "\n",
    "# How long does this take for each image? \n",
    "# How long does this take for all images?\n",
    "    \n",
    "# What folders does this pull from?\n",
    "# Do i need to move folders? \n",
    "\n",
    "# What is the output?\n",
    "\n",
    "\n",
    "# What function do I need to run to get a total output? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'  #to practice on how pipeline will run with multiple images \n",
    "\n",
    "def invwarp(directory):\n",
    "    return subprocess.run([\"invwarp\", \"--ref=\"+directory+\"/T1.nii.gz\", \"--warp=\"+directory+\"/T1_to_MNI_nonlin_field.nii.gz\", \"--out=\"+directory+\"/Warps/\"+\"std_subject_space\", \"--verbose\"], capture_output=True)\n",
    "\n",
    "\n",
    "def applywarp_cort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "def applywarp_subcort(directory):\n",
    "    return subprocess.run([\"applywarp\",\"--ref=\"+directory+\"/T1.nii.gz\", \"--in=/usr/local/fsl/data/atlases/HarvardOxford/HarvardOxford-sub-maxprob-thr50-2mm.nii.gz\", \n",
    "               \"--warp=\"+directory+\"/Warps/\"+\"std_subject_space.nii.gz\", \n",
    "               \"--out=\"+directory+\"/Warps/\"+\"subcort_HO_in_subj_t1_space.nii.gz\",  \"--interp=nn\"], capture_output=True)\n",
    "\n",
    "\n",
    "def apply_warps(path):\n",
    "    \n",
    "    folder = os.path.join(path, \"Warps\") \n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    invwarp(path)\n",
    "    print(path + ' invwarp done')\n",
    "    time.sleep(3)\n",
    "    applywarp_cort(path)\n",
    "    print(path + ' cort done')\n",
    "    applywarp_subcort(path)\n",
    "    print(path + ' subcort done')\n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=10)(delayed(apply_warps)(file) for file in glob.glob(os.path.join(directory, '*.anat')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fslstats -K subcort_HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the subcortical regions\n",
    "# fslstats -K HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the cortical regions\n",
    "\n",
    "\n",
    "def get_vols(vol_files, label):\n",
    "    \n",
    "    patient = {}\n",
    "    \n",
    "    for file in vol_files:\n",
    "        \n",
    "        path = os.path.basename(file)\n",
    "        \n",
    "        label_vals = [10, 11, 12, 13, 16, 17, 18, 26, 49, 50, 51, 52, 53, 54, 58]\n",
    "        length = len(label_vals)\n",
    "\n",
    "        vols = {}\n",
    "        \n",
    "        \n",
    "        for i in label_vals:\n",
    "            out = sout = subprocess.Popen([\"fslstats\", file, \"-l\", str((i+0.5)-1), \"-u\", str(i+0.5), \"-V\"], \n",
    "                   stdout=subprocess.PIPE, \n",
    "                   stderr=subprocess.STDOUT)\n",
    "            stdout,stderr = out.communicate()\n",
    "            vols[\"LABEL\"] = label\n",
    "            vols[str(i)] = [float(str(stdout.split()[0])[2:-1]), float(str(stdout.split()[1])[2:-1])]\n",
    "\n",
    "        patient[path[:-29]] = vols\n",
    "    \n",
    "    return patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fslstats -K subcort_HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the subcortical regions\n",
    "# fslstats -K HO_in_subj_t1_space.nii.gz T1.nii.gz -M -V  # for the cortical regions\n",
    "\n",
    "# I need to\n",
    "# 1. feed in the parent directory\n",
    "# 2. feed in the label for each file and where the file is located\n",
    "# 3. apply fslstats for cort and applywarp_subcort\n",
    "# 4. collect the outputs and feed into dictionary\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def getVol_Dataframe(directory):\n",
    "\n",
    "    brain_volumes = pd.DataFrame()\n",
    "\n",
    "    for file in glob.glob(os.path.join(directory)):\n",
    "\n",
    "        path = os.path.basename(file)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        # vols = {}\n",
    "\n",
    "        # for i in label_vals:\n",
    "        #     print(i)\n",
    "        #     out_cort = sout = subprocess.Popen([\"fslstats\", \"-K\", \"./Warps/HO_in_subj_t1_space.nii.gz\", \"T1.nii.gz\", \"-V\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        #     stdout,stderr = out.communicate()\n",
    "        #     out_subcort = sout = subprocess.Popen([\"fslstats\", \"-K\", \"./Warps/subcort_HO_in_subj_t1_space.nii.gz\", \"T1.nii.gz\", \"-V\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        #     stdout,stderr = out.communicate()\n",
    "\n",
    "        #     vols[\"LABEL\"] = label\n",
    "        #     vols[str(i)] = [float(str(stdout.split()[0])[2:-1]), float(str(stdout.split()[1])[2:-1])]\n",
    "\n",
    "        # patient[path[:-29]] = vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "directory = '/mnt/md0/cads-phd/explainbrainROI/spr_mini_try_again/'  #to practice on how pipeline will run with multiple images \n",
    "\n",
    "for file in glob.glob(os.path.join(directory)):\n",
    "    \n",
    "    path = os.path.basename(file)\n",
    "\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
